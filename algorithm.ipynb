{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\".\")\n",
    "import re\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "from datetime import timedelta\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.max_columns', None)\n",
    "def thousands_formatter_func(x, pos):\n",
    "    return f'{int(x / 1e3)}K'\n",
    "thousand_formatter = FuncFormatter(thousands_formatter_func)\n",
    "def decimal_percentage_formatter_func(x, pos):\n",
    "    return f'{int(x * 100)}%'\n",
    "decimal_percentage_formatter = FuncFormatter(decimal_percentage_formatter_func)\n",
    "def percentage_formatter_func(x, pos):\n",
    "    return f'{int(x)}%'\n",
    "percentage_formatter = FuncFormatter(percentage_formatter_func)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bombs = pd.read_csv('data/processed_csv/df_bombs.csv', delimiter=',', encoding='latin-1', index_col=0)\n",
    "df_of = pd.read_csv('data/processed_csv/df_of.csv', delimiter=',', encoding='latin-1')\n",
    "df_operators = pd.read_csv('data/processed_csv/df_operators.csv', delimiter=',', encoding='latin-1')\n",
    "df_operators_participation = pd.read_csv('data/processed_csv/df_operators_participation.csv', delimiter=',', encoding='latin-1')\n",
    "\n",
    "df_bombs['start_date'] = pd.to_datetime(df_bombs['start_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_bombs['end_date'] = pd.to_datetime(df_bombs['end_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_of['start_date'] = pd.to_datetime(df_of['start_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_of['end_date'] = pd.to_datetime(df_of['end_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of.line = df_of.line.replace({\"LÃ\\x8dNEA 2\": \"LINEA 2\", \"LINEA_2\": \"LINEA 2\", \"LINEA_4\": \"LINEA 4\", \"LÃ\\x8dNEA 1\": \"LINEA 1\", \"LINEA_1\": \"LINEA 1\", \"LINEA_6\": \"LINEA 6\",\n",
    "                    \"LINEA_3\": \"LINEA 3\", \"LÃ\\x8dNEA KIVU\": \"LINEA KIVU\", \"PREFILTRO L-1\": \"PREFILTRO_L-1\", \"PREFILTRO L-6\": \"PREFILTRO_L-6\",\n",
    "                        \"LINEA_7\": \"LINEA 7\", \"LINEA 8 IML\": \"LINEA_8_IML\"})\n",
    "df_operators_participation.line = df_operators_participation.line.replace({\"LÃ\\x8dNEA 2\": \"LINEA 2\", \"LINEA_2\": \"LINEA 2\", \"LINEA_4\": \"LINEA 4\", \"LÃ\\x8dNEA 1\": \"LINEA 1\", \"LINEA_1\": \"LINEA 1\", \"LINEA_6\": \"LINEA 6\",\n",
    "                    \"LINEA_3\": \"LINEA 3\", \"LÃ\\x8dNEA KIVU\": \"LINEA KIVU\", \"PREFILTRO L-1\": \"PREFILTRO_L-1\", \"PREFILTRO L-6\": \"PREFILTRO_L-6\",\n",
    "                        \"LINEA_7\": \"LINEA 7\", \"LINEA 8 IML\": \"LINEA_8_IML\"})\n",
    "\n",
    "df_of.line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(text):\n",
    "    # Agrega los caracteres especiales que deseas eliminar, incluyendo los tildes\n",
    "    special_chars = r\"[^\\w\\sáéíóúÁÉÍÓÚñÑÃ]\"\n",
    "    text_without_special_chars = re.sub(special_chars, '', text)\n",
    "    # Agrega aquí cualquier otro reemplazo adicional que desees realizar\n",
    "    return text_without_special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of['line'].apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[\"weekday\"] = df_of[\"start_date\"].dt.weekday.astype(\"category\")\n",
    "df_of[\"turn\"] = df_of[\"start_date\"].apply(lambda x: 'AM' if x.hour < 14 else 'PM')\n",
    "df_of[\"month\"] = df_of[\"start_date\"].dt.month.astype(\"category\")\n",
    "df_of[\"year\"] = df_of[\"start_date\"].dt.year.astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Cargar el modelo desde el archivo\n",
    "with open('classifier_model.pickle', 'rb') as file:\n",
    "    classifier_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.feature_names_in_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def get_modified_dataframe():\n",
    "    # Ruta completa del archivo CSV\n",
    "    ruta_archivo = 'data/processed_csv/df_operators_participation.csv'\n",
    "\n",
    "    # Leer el archivo CSV en un DataFrame\n",
    "    df_operators_participation = pd.read_csv(ruta_archivo)\n",
    "\n",
    "    df_operators_participation['line'] = df_operators_participation['line'].apply(lambda x: remove_accents(x))\n",
    "\n",
    "    # Eliminar los registros que contienen 'PREFILTRO' en la columna 'line'\n",
    "    df_operators_participation = df_operators_participation[~df_operators_participation['line'].str.contains('PREFILTRO')]\n",
    "\n",
    "    return df_operators_participation\n",
    "\n",
    "def active_operators_by_lines(dataframe, available_operators, available_lines):\n",
    "    lineas_operarios_disponibles = {}\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        operador = str(row['operator_id'])\n",
    "        linea = row['line']\n",
    "\n",
    "        if linea in available_lines and operador in available_operators:\n",
    "            if linea in lineas_operarios_disponibles:\n",
    "                if operador not in lineas_operarios_disponibles[linea]:\n",
    "                    lineas_operarios_disponibles[linea].append(operador)\n",
    "            else:\n",
    "                lineas_operarios_disponibles[linea] = [operador]\n",
    "\n",
    "    return lineas_operarios_disponibles\n",
    "\n",
    "\n",
    "def active_lines_by_order(dataframe, available_lines, orders):\n",
    "    def lineas_por_bomba(dataframe):\n",
    "        bombas_lineas = {}\n",
    "\n",
    "        for index, row in dataframe.iterrows():\n",
    "            linea = row['line']\n",
    "            bomba = row['bomb_type']\n",
    "\n",
    "            if bomba in bombas_lineas:\n",
    "                if linea not in bombas_lineas[bomba]:\n",
    "                    bombas_lineas[bomba].append(linea)\n",
    "            else:\n",
    "                bombas_lineas[bomba] = [linea]\n",
    "\n",
    "        return bombas_lineas\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "    df['line'] = df['line'].apply(lambda x: remove_accents(x))\n",
    "\n",
    "    bombas_lineas = lineas_por_bomba(df)\n",
    "\n",
    "    active_lines = {}\n",
    "\n",
    "    for order in orders:\n",
    "        order_id = order['id']\n",
    "        bomba = order['bomb_type']\n",
    "        valid_lines = [line for line in available_lines if line in bombas_lineas.get(bomba, [])]\n",
    "\n",
    "        if valid_lines:\n",
    "            active_lines[order_id] = valid_lines\n",
    "\n",
    "    return active_lines\n",
    "\n",
    "available_operators = ['37', '5004', '5033', '8164', '8830', '8833', '8860', '8894', '9104', '9142', '9254', '9279', '9280']\n",
    "available_lines = ['LINEA 3', 'LINEA 2', 'LINEA KIVU', 'LINEA 4', 'LINEA 7', 'LINEA 1', 'LINEA 6' ]\n",
    "\n",
    "ORDERS = [\n",
    "    {'id': 5365043,\n",
    "    'bomb_type': '73676',\n",
    "    'good_qty': 79.0,\n",
    "    'theorical_time': 9.35},\n",
    "    {'id': 5366240,\n",
    "    'bomb_type': '01205-0810',\n",
    "    'good_qty': 17.0,\n",
    "    'theorical_time': 80.0},\n",
    "    {'id': 5371350,\n",
    "    'bomb_type': '65557H',\n",
    "    'good_qty': 30.0,\n",
    "    'theorical_time': 6.87},\n",
    "    {'id': 5372841,\n",
    "    'bomb_type': '66047-0890',\n",
    "    'good_qty': 6.0,\n",
    "    'theorical_time': 66.0},\n",
    "    {'id': 5374961,\n",
    "    'bomb_type': '25464',\n",
    "    'good_qty': 60.0,\n",
    "    'theorical_time': 7.1},\n",
    "    {'id': 5375947,\n",
    "    'bomb_type': '08003-0810',\n",
    "    'good_qty': 9.0,\n",
    "    'theorical_time': 21.54},\n",
    "    {'id': 5376189,\n",
    "    'bomb_type': '6862',\n",
    "    'good_qty': 66.0,\n",
    "    'theorical_time': 8.5}]\n",
    "\n",
    "df_operators_participation = get_modified_dataframe()\n",
    "\n",
    "active_operators_by_line = active_operators_by_lines(df_operators_participation, available_operators, available_lines)\n",
    "\n",
    "active_lines_by_order = active_lines_by_order(df_operators_participation, available_lines, ORDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_operators_by_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_lines_by_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bombs_constraint = pd.read_excel('data/to_load/constraint/bombs_constraint.xlsx')\n",
    "df_bombs_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bombs_constraint['Linea'] = df_bombs_constraint['Linea'].apply(lambda x: [i.strip() for i in x.split(',')])\n",
    "\n",
    "diccionario = df_bombs_constraint.set_index('Bomb_type')['Linea'].to_dict()\n",
    "\n",
    "print(diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_lines_by_order = {}\n",
    "\n",
    "for order in ORDERS:\n",
    "    bomb_type = str(order['bomb_type'])  # asegurarse de que bomb_type sea string\n",
    "    order_id = order['id']\n",
    "    if bomb_type in diccionario:\n",
    "        active_lines_by_order[order_id] = diccionario[bomb_type]\n",
    "    else:\n",
    "        active_lines_by_order[order_id] = []  # si el bomb_type no está en el diccionario, añadir una lista vacía\n",
    "\n",
    "print(active_lines_by_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bombs_constraint.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_constraint = pd.read_excel('data/to_load/constraint/operators_constraint.xlsx')\n",
    "df_operators_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_constraint['Lineas'] = df_operators_constraint['Lineas'].apply(lambda x: [i.strip() for i in x.split(',')])\n",
    "\n",
    "diccionario = df_operators_constraint.set_index('Operario')['Lineas'].to_dict()\n",
    "\n",
    "print(diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_by_operator = {}\n",
    "\n",
    "for _, row in df_operators_constraint.iterrows():\n",
    "    for line in row['Lineas']:\n",
    "        if line in lines_by_operator:\n",
    "            lines_by_operator[line].append(row['Operario'])\n",
    "        else:\n",
    "            lines_by_operator[line] = [row['Operario']]\n",
    "\n",
    "lines_by_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINE = 'LINEA_3', 'LINEA_2', 'LINEA_KIVU', 'LINEA 4', 'LINEA_7', 'LINEA_1', 'LINEA_6' \n",
    "# CUMPLE = '0', '0', '0', '0', '0', '1', '1' \n",
    "example_orders = [5365043, 5371350, 5372841, 5374961, 5376189, 5366240, 5375947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[df_of['order'].isin(example_orders)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_lines_by_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDERS = [\n",
    "#     {'id': 5160396, 'good_qty': 100, 'theorical_time': 2.5, 'bomb_type': '01224-0890'},\n",
    "#     {'id': 5169247, 'good_qty': 200, 'theorical_time': 3.0, 'bomb_type': '1210'},\n",
    "#     {'id': 5171973, 'good_qty': 150, 'theorical_time': 2.0, 'bomb_type': '1197'},\n",
    "# ]\n",
    "\n",
    "# ORDERS_DICT = {\n",
    "#     5160396: {'good_qty': 100, 'theorical_time': 2.5, 'registers_qty': 30, 'operators_distinct_qty': 2, 'days_accumulated_experience': 102, 'OFs_accumulated_experience': 50},\n",
    "#     5169247: {'good_qty': 200, 'theorical_time': 3.0, 'registers_qty': 10, 'operators_distinct_qty': 3, 'days_accumulated_experience': 102, 'OFs_accumulated_experience': 50},\n",
    "#     5171973: {'good_qty': 150, 'theorical_time': 2.0, 'registers_qty': 50, 'operators_distinct_qty': 4, 'days_accumulated_experience': 102, 'OFs_accumulated_experience': 50},\n",
    "# }\n",
    "\n",
    "\n",
    "# available_operators = ['37', '5004', '5033', '8164', '8830', '8833', '8860', '8894', '9104', '9142', '9254', '9279', '9280']\n",
    "# available_lines = ['LINEA 3', 'LINEA 2', 'LINEA KIVU', 'LINEA 4', 'LINEA 7', 'LINEA 1', 'LINEA 6' ]\n",
    "\n",
    "# active_lines_by_order = {\n",
    "#     5160396: ['LINEA_1', 'LINEA_2'],\n",
    "#     5169247: ['LINEA_1', 'LINEA_2', 'LINEA_3'],\n",
    "#     5171973: ['LINEA_2', 'LINEA_3']\n",
    "# }\n",
    "\n",
    "# active_operators_by_line = {\n",
    "#     'LINEA_1': [9395, 9391, 9378],\n",
    "#     'LINEA_2': [9380, 9378, 9352],\n",
    "#     'LINEA_3': [9349, 9391]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools, algorithms\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_to_classifier_model(order, operators, line, available_operators, available_lines):\n",
    "    # DataFrame de ceros con las columnas que necesitamos\n",
    "    return True\n",
    "    columns = ['good_qty', 'theorical_time', 'registers_qty', 'operators_distinct_qty'] + ['operator_' + str(i) for i in available_operators] + ['line_' + line for line in available_lines] + ['days_accumulated_experience', 'OFs_accumulated_experience']\n",
    "    order_df = pd.DataFrame(np.zeros((1, len(columns))), columns=columns)\n",
    "    # Actualiza las columnas relevantes\n",
    "    order_df['good_qty'] = order['good_qty']\n",
    "    order_df['theorical_time'] = order['theorical_time']\n",
    "    order_df['registers_qty'] = order['registers_qty']\n",
    "    order_df['operators_distinct_qty'] = len(operators)\n",
    "    order_df['days_accumulated_experience'] = order['days_accumulated_experience']\n",
    "    order_df['OFs_accumulated_experience'] = order['OFs_accumulated_experience']\n",
    "    for operator in operators:\n",
    "        order_df['operator_' + str(operator)] = 1\n",
    "\n",
    "    order_df['line_' + line] = 1\n",
    "    return order_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_individuals = set()\n",
    "evaluations_count = 0\n",
    "def main():\n",
    "    global evaluations_count, unique_individuals\n",
    "    unique_individuals = set()\n",
    "    evaluations_count = 0\n",
    "    def individual_to_str(individual):\n",
    "        return str(sorted((assignment['order'], tuple(sorted(assignment['operators'])), assignment['line']) for assignment in individual))\n",
    "\n",
    "    def evaluate(individual):\n",
    "        global evaluations_count, unique_individuals\n",
    "        evaluations_count += 1\n",
    "        # Agrega el individuo al conjunto de individuos únicos\n",
    "        unique_individuals.add(individual_to_str(individual))\n",
    "\n",
    "        success_count = 0\n",
    "        total_probability = 0.0\n",
    "        for assignment in individual:\n",
    "\n",
    "            order_id = assignment['order']\n",
    "            operators = assignment['operators']\n",
    "            line = assignment['line']\n",
    "\n",
    "            # Encuentra la orden correspondiente en la lista de órdenes\n",
    "            order = next(order for order in ORDERS if order['id'] == order_id)\n",
    "            \n",
    "            order_df = pd.DataFrame({\n",
    "                'good_qty': [order['good_qty']],\n",
    "                'theorical_time': [order['theorical_time']],\n",
    "                'operators': [operators],\n",
    "                'line': [line],\n",
    "            })\n",
    "            format_df_to_classifier_model(order, operators, line, available_operators, available_lines)\n",
    "            # prediction = classifier_model.predict(order_df)[0]\n",
    "            prediction_proba = random.random()\n",
    "            prediction = 1 if prediction_proba > 0.5 else 0\n",
    "\n",
    "            if prediction == 1:  # Si la OF es exitosa\n",
    "                success_count += 1\n",
    "            total_probability += prediction_proba\n",
    "        \n",
    "        fitness = success_count + (total_probability / 10000) \n",
    "        return fitness,\n",
    "\n",
    "    operator_combos = []\n",
    "    max_operators_per_order = 4\n",
    "    for r in range(1, max_operators_per_order + 1):\n",
    "        operator_combos.extend(itertools.combinations(available_operators, r))\n",
    "    \n",
    "    # Definimos los tipos para el problema de optimización\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # Maximizamos la función de fitness\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "\n",
    "    \n",
    "\n",
    "    def initIndividual():\n",
    "        attempts = 0\n",
    "        max_attempts = 10000  # ajusta este número según sea necesario\n",
    "        while attempts < max_attempts:\n",
    "            individual = []\n",
    "            available_operators_for_this_individual = available_operators.copy()  # Crear una copia de la lista de operadores disponibles\n",
    "            available_lines_for_this_individual = available_lines.copy()  # Crear una copia de la lista de líneas disponibles\n",
    "            for order in ORDERS:\n",
    "                # Elegir una línea que aún no se haya asignado\n",
    "                posible_lines_for_this_order = [line for line in available_lines_for_this_individual if line in active_lines_by_order[order['id']]]\n",
    "                if not posible_lines_for_this_order:  # Si no hay más líneas disponibles, no podemos generar un individuo válido\n",
    "                    break\n",
    "                line = random.choice(posible_lines_for_this_order)\n",
    "                available_lines_for_this_individual.remove(line)  # La línea ya no está disponible para las siguientes órdenes\n",
    "\n",
    "                # Elegir un conjunto de operadores que aún no se hayan asignado\n",
    "                posible_operators_for_this_line = [operator for operator in available_operators_for_this_individual if operator in active_operators_by_line[line]]\n",
    "                valid_operator_combos = [combo for combo in operator_combos if set(combo).issubset(posible_operators_for_this_line)]\n",
    "                if not valid_operator_combos:  # Si no hay más operadores disponibles, no podemos generar un individuo válido\n",
    "                    break\n",
    "                operators = random.choice(valid_operator_combos)\n",
    "                for operator in operators:\n",
    "                    available_operators_for_this_individual.remove(operator)  # El operador ya no está disponible para las siguientes órdenes\n",
    "\n",
    "                individual.append({'order': order['id'], 'operators': operators, 'line': line})\n",
    "\n",
    "            if len(individual) == len(ORDERS):  # si el individuo es válido (tiene todas las órdenes)\n",
    "                print(f'[INIT INDIVIDUAL]: {attempts}')\n",
    "                print(individual)\n",
    "                return creator.Individual(individual)\n",
    "\n",
    "            attempts += 1\n",
    "\n",
    "        # Si hemos llegado a este punto, es porque todos los intentos de generar un individuo válido han fallado.\n",
    "        raise Exception(f\"No se pudo generar un individuo válido después de {max_attempts} intentos.\")\n",
    "\n",
    "\n",
    "\n",
    "    toolbox.register(\"individual\", initIndividual)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    # Definimos los operadores genéticos\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "\n",
    "    # Definimos la función de crossovr\n",
    "    def custom_crossover(ind1, ind2):\n",
    "        # Crea copias de los individuos para no modificar los originales\n",
    "        modified = False\n",
    "        new_ind1 = copy.deepcopy(ind1)\n",
    "        new_ind2 = copy.deepcopy(ind2)\n",
    "        \n",
    "        for order in ORDERS:\n",
    "            order_id = order['id']\n",
    "\n",
    "            # Encuentra las asignaciones para esta orden en ambos individuos\n",
    "            assignment1 = next(assignment for assignment in new_ind1 if assignment['order'] == order_id)\n",
    "            assignment2 = next(assignment for assignment in new_ind2 if assignment['order'] == order_id)\n",
    "            \n",
    "\n",
    "            # No se requiere validación de order y line porque se garantiza que los individuos son válidos\n",
    "            # Solamente se valida el intercambio de operadores\n",
    "            if (set(assignment2['operators']).issubset(active_operators_by_line[assignment1['line']])\n",
    "                    and set(assignment1['operators']).issubset(active_operators_by_line[assignment2['line']])):\n",
    "                # Intercambia las asignaciones de operadores y líneas\n",
    "                assignment1['operators'], assignment2['operators'] = assignment2['operators'], assignment1['operators']\n",
    "                assignment1['line'], assignment2['line'] = assignment2['line'], assignment1['line']\n",
    "                modified = True\n",
    "        \n",
    "        if not modified:\n",
    "            print('[ERROR-CROSSOVER NOT MODIFIED]:')\n",
    "            print(new_ind1)\n",
    "            print(new_ind2)\n",
    "            return ind1, ind2\n",
    "\n",
    "        # Verifica si las nuevas asignaciones violan las restricciones\n",
    "        violation = False\n",
    "        for new_ind in [new_ind1, new_ind2]:\n",
    "            for i in range(len(new_ind1)):\n",
    "                for j, assignment in enumerate(new_ind):\n",
    "                    if j != i:\n",
    "                        # Verifica si la nueva línea se repite en otras asignaciones\n",
    "                        if new_ind[i]['line'] == assignment['line']:\n",
    "                            violation = True\n",
    "                            break\n",
    "\n",
    "                        # Verifica si los nuevos operadores se repiten en otras asignaciones\n",
    "                        if any(op in new_ind[i]['operators'] for op in assignment['operators']):\n",
    "                            violation = True\n",
    "                            break\n",
    "        if violation:\n",
    "            print('[ERROR-CROSSOVER VIOLATION]:')\n",
    "            print(new_ind1)\n",
    "            print(new_ind2)\n",
    "            return ind1, ind2\n",
    "        \n",
    "        print('[CROSSOVER GENERATED]')\n",
    "        return new_ind1, new_ind2\n",
    "\n",
    "    toolbox.register(\"mate\", custom_crossover)\n",
    "\n",
    "    def custom_mutation(individual, indpb):\n",
    "        attempts = 0\n",
    "        for i in range(len(individual)):\n",
    "            if random.random() < indpb:\n",
    "                attempts = 0\n",
    "                max_attempts = 10000  # ajusta este número según sea necesario\n",
    "                while attempts < max_attempts:\n",
    "                    # Selecciona una nueva línea dentro de las posibles:\n",
    "                    new_line = random.choice(active_lines_by_order[individual[i]['order']])\n",
    "\n",
    "                    # Verifica si la nueva asignación viola las restricciones\n",
    "                    violation = False\n",
    "                    posible_operators_for_this_line = [operator for operator in active_operators_by_line[new_line]]\n",
    "                    valid_operator_combos = [combo for combo in operator_combos if set(combo).issubset(posible_operators_for_this_line)]\n",
    "                    new_operators = random.choice(valid_operator_combos)\n",
    "                    for j, assignment in enumerate(individual):\n",
    "                        if j != i:\n",
    "                            # Verifica si la nueva línea se repite en otras asignaciones\n",
    "                            if new_line == assignment['line']:\n",
    "                                violation = True\n",
    "                                break\n",
    "\n",
    "                            # Verifica si los nuevos operadores se repiten en otras asignaciones\n",
    "                            if any(op in new_operators for op in assignment['operators']):\n",
    "                                violation = True\n",
    "                                break\n",
    "\n",
    "                    if not violation:\n",
    "                        # Si la asignación es válida, actualiza la asignación en el individuo\n",
    "                        individual[i]['line'] = new_line\n",
    "                        individual[i]['operators'] = tuple(new_operators)  # Convierte la lista en una tupla\n",
    "                        break\n",
    "\n",
    "                    attempts += 1\n",
    "        print(f'[MUTATION GENERATED]: {attempts or 0} intentos')\n",
    "        return individual,\n",
    "\n",
    "    toolbox.register(\"mutate\", custom_mutation, indpb=0.4)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # Inicializamos la población y ejecutamos el algoritmo genético\n",
    "    population = toolbox.population(n=50)\n",
    "    result = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=40, verbose=False)\n",
    "    best_individual = tools.selBest(result[0], 3)[0]\n",
    "    best_fitness = best_individual.fitness.values\n",
    "\n",
    "    print('···· RESULTADOS ····')\n",
    "    print(f'Se han realizado {evaluations_count} evaluaciones.')\n",
    "    # print(f'Se han realizado {len(unique_individuals)} evaluaciones únicas.')\n",
    "    print(f'El mejor individuo es: {best_individual}')\n",
    "    def selectUnique(individuals, k):\n",
    "        unique_individuals = []\n",
    "        for ind in individuals:\n",
    "            if not any(ind2 == ind for ind2 in unique_individuals):\n",
    "                unique_individuals.append(ind)\n",
    "            if len(unique_individuals) == k:\n",
    "                break\n",
    "        return unique_individuals\n",
    "\n",
    "    unique_individuals = selectUnique(tools.selNSGA2(result[0], len(result[0])), 10)\n",
    "    best_fitnesses = [ind.fitness.values for ind in unique_individuals]\n",
    "\n",
    "    for i in range(len(unique_individuals)):\n",
    "        print('########################')\n",
    "        print(f'\\nMejor individuo {i+1}:')\n",
    "        print(f'Valor de fitness: {best_fitnesses[i]}')\n",
    "        for assignment in unique_individuals[i]:\n",
    "            order_id = assignment['order']\n",
    "            operators = assignment['operators']\n",
    "            line = assignment['line']\n",
    "            print(f'  Orden: {order_id}, Operadores: {operators}, Línea: {line}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [{'order': 5160396, 'operators': (1, 2, 9), 'line': 'LINEA_3'}, {'order': 5169247, 'operators': (3, 4), 'line': 'LINEA_2'}, {'order': 5171973, 'operators': (3,), 'line': 'LINEA_4'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(example)):\n",
    "    violation = False\n",
    "    for j, assignment in enumerate(example):\n",
    "        if j != i:\n",
    "            # Verifica si la nueva línea se repite en otras asignaciones\n",
    "            if example[i]['line'] == assignment['line']:\n",
    "                violation = True\n",
    "                break\n",
    "\n",
    "            # Verifica si los nuevos operadores se repiten en otras asignaciones\n",
    "            if any(op in example[i]['operators'] for op in assignment['operators']):\n",
    "                violation = True\n",
    "                break\n",
    "print(violation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = ['5376213', '5372454', '5376066', '5373384', '5379842', '5382059', '5374960']\n",
    "orders = [5376213, 5372454, 5376066, 5373384, 5379842, 5382059, 5374960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of.line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['LINEA_2', 'LINEA 4', 'LINEA 6', 'LINEA_1', 'LINEA_3', 'LINEA_KIVU', 'LINEA_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bombs.reset_index(inplace=True)\n",
    "df_bombs[df_bombs['order'].isin(orders)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[(df_of['year'] == 2023) & (df_of['line'] == 'LINEA 6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINE = 'LINEA_3', 'LINEA_2', 'LINEA_KIVU', 'LINEA 4', 'LINEA_7', 'LINEA_1', 'LINEA_6' \n",
    "# CUMPLE = '0', '0', '0', '0', '0', '1', '1' \n",
    "orders = [5365043, 5371350, 5372841, 5374961, 5376189, 5366240, 5375947]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[df_of['order'].isin(orders)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bombs[df_bombs['order'].isin(orders)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluidra_poetry_kernel",
   "language": "python",
   "name": "fluidra_poetry_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
