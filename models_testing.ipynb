{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\".\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "from datetime import timedelta\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.max_columns', None)\n",
    "def thousands_formatter_func(x, pos):\n",
    "    return f'{int(x / 1e3)}K'\n",
    "thousand_formatter = FuncFormatter(thousands_formatter_func)\n",
    "def decimal_percentage_formatter_func(x, pos):\n",
    "    return f'{int(x * 100)}%'\n",
    "decimal_percentage_formatter = FuncFormatter(decimal_percentage_formatter_func)\n",
    "def percentage_formatter_func(x, pos):\n",
    "    return f'{int(x)}%'\n",
    "percentage_formatter = FuncFormatter(percentage_formatter_func)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bombs = pd.read_csv('data/processed_csv/df_bombs.csv', delimiter=',', encoding='latin-1', index_col=0)\n",
    "df_of = pd.read_csv('data/processed_csv/df_of.csv', delimiter=',', encoding='latin-1')\n",
    "df_operators = pd.read_csv('data/processed_csv/df_operators.csv', delimiter=',', encoding='latin-1')\n",
    "df_operators_participation = pd.read_csv('data/processed_csv/df_operators_participation.csv', delimiter=',', encoding='latin-1')\n",
    "\n",
    "df_bombs['start_date'] = pd.to_datetime(df_bombs['start_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_bombs['end_date'] = pd.to_datetime(df_bombs['end_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_of['start_date'] = pd.to_datetime(df_of['start_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_of['end_date'] = pd.to_datetime(df_of['end_date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of.line = df_of.line.replace({\"LÃ\\x8dNEA 2\": \"LINEA_2\", \"LINEA_4\": \"LINEA_4\", \"LÃ\\x8dNEA 1\": \"LINEA_1\", \"LINEA_6\": \"LINEA_6\",\n",
    "                    \"LINEA 3\": \"LINEA_3\", \"LÃ\\x8dNEA KIVU\": \"LINEA_KIVU\", \"PREFILTRO L-1\": \"PREFILTRO_L-1\", \"PREFILTRO L-6\": \"PREFILTRO_L-6\",\n",
    "                        \"LINEA 7\": \"LINEA_7\", \"LINEA 8 IML\": \"LINEA_8_IML\"})\n",
    "df_operators_participation.line = df_operators_participation.line.replace({\"LÃ\\x8dNEA 2\": \"LINEA_2\", \"LINEA_4\": \"LINEA_4\", \"LÃ\\x8dNEA 1\": \"LINEA_1\", \"LINEA_6\": \"LINEA_6\",\n",
    "                    \"LINEA 3\": \"LINEA_3\", \"LÃ\\x8dNEA KIVU\": \"LINEA_KIVU\", \"PREFILTRO L-1\": \"PREFILTRO_L-1\", \"PREFILTRO L-6\": \"PREFILTRO_L-6\",\n",
    "                        \"LINEA 7\": \"LINEA_7\", \"LINEA 8 IML\": \"LINEA_8_IML\"})\n",
    "\n",
    "df_of.line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(text):\n",
    "    # Agrega los caracteres especiales que deseas eliminar, incluyendo los tildes\n",
    "    special_chars = r\"[^\\w\\sáéíóúÁÉÍÓÚñÑÃ]\"\n",
    "    text_without_special_chars = re.sub(special_chars, '', text)\n",
    "    # Agrega aquí cualquier otro reemplazo adicional que desees realizar\n",
    "    return text_without_special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of['line'].apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[\"weekday\"] = df_of[\"start_date\"].dt.weekday.astype(\"category\")\n",
    "df_of[\"turn\"] = df_of[\"start_date\"].apply(lambda x: 'AM' if x.hour < 14 else 'PM')\n",
    "df_of[\"month\"] = df_of[\"start_date\"].dt.month.astype(\"category\")\n",
    "df_of[\"year\"] = df_of[\"start_date\"].dt.year.astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribución Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_of.sort_values(by='performance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=data, x='performance', bins=20, kde=True)\n",
    "plt.xlabel('Performance')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(f'Distribución de la performance de OFs')\n",
    "plt.xticks(rotation=70, ha='right', fontsize=8)\n",
    "plt.gca().legend().set_visible(True)\n",
    "plt.gca().xaxis.set_major_formatter(decimal_percentage_formatter_func)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribución de Participación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_operators_participation.participation_percentage.quantile(0.02))\n",
    "print(df_operators_participation.participation_percentage.quantile(0.05))\n",
    "print(df_operators_participation.participation_percentage.quantile(0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_operators_participation.sort_values(by='participation_percentage', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=data, x='participation_percentage', bins=40, kde=True)\n",
    "plt.xlabel('Performance')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(f'Distribución de la performance de OFs')\n",
    "plt.xticks(rotation=70, ha='right', fontsize=8)\n",
    "plt.gca().xaxis.set_major_formatter(percentage_formatter)\n",
    "plt.gca().legend().set_visible(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_operators_participation[\n",
    "    df_operators_participation.participation_percentage <= 40\n",
    "].sort_values(by='participation_percentage', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=data, x='participation_percentage', bins=20, kde=True)\n",
    "plt.xlabel('Performance')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(f'Distribución de la performance de OFs')\n",
    "plt.xticks(rotation=70, ha='right', fontsize=8)\n",
    "plt.gca().xaxis.set_major_formatter(percentage_formatter)\n",
    "plt.gca().legend().set_visible(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supuestos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supuestos\n",
    "* Se asume un corte de performance aceptable para una OF sobre el  80%\n",
    "* Se asume una participación mínima deun 5% del tiempo de un operador en una OF para considerar que trabajó en ella\n",
    "* Para entrenar, se asume que la cantidad de bombas realizadas (good_qty) era lo planificado a hacer para la OF\n",
    "* Se quita del análisis líneas que no son de interés para el cliente (LINEA 8 IML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_model = df_of.copy()\n",
    "df_operators_participation_model = df_operators_participation.copy()\n",
    "df_operators_model = df_operators.copy()\n",
    "\n",
    "perfomance_cutoff = 0.88\n",
    "participation_cutoff = 0.05\n",
    "exclude_lines= ['LINEA_8_IML']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_model.drop(['operators_distinct_ids', 'plan_qty', 'theorical_qty_round', 'performance_round', 'total_good_qty', 'total_bad_qty'], axis=1, inplace=True)\n",
    "df_of_model = df_of_model[df_of_model.line.isin(exclude_lines) == False]\n",
    "df_operators_participation_model = df_operators_participation_model[df_operators_participation_model.line.isin(exclude_lines) == False]  \n",
    "print(df_of_model.describe())\n",
    "df_of_model.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos las OFs que no tenían cantidad palnificada *good_qty == 0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_model = df_of_model[df_of_model.good_qty != 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetado de OFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_model['achieve_performance'] = df_of_model['performance'].apply(lambda x: 1 if x >= perfomance_cutoff else 0)\n",
    "df_of_model.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetado participacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation_model['participation_indicator'] = df_operators_participation_model['participation_percentage'].apply(lambda x: 1 if x >= participation_cutoff*100 else 0)\n",
    "df_operators_participation_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotear el dataframe df_operators_participation para obtener las columnas de operadores\n",
    "df_operators_participation_model.drop_duplicates(inplace=True)\n",
    "df_pivot = df_operators_participation_model.pivot(index='order', columns='operator_id', values='participation_indicator')\n",
    "df_pivot = df_pivot.fillna(0)\n",
    "df_pivot.columns = ['operator_' + str(col) for col in df_pivot.columns]\n",
    "df_pivot = df_pivot.astype(int)\n",
    "print(df_pivot.shape)\n",
    "df_pivot.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregamos experiencia de operadores como dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation_model = df_operators_participation_model.sort_values(by=['operator_id', 'production_date'], ascending=True)\n",
    "df_operators_participation_model['accumulated_experience'] = 0\n",
    "for index, row in df_operators_participation_model.iterrows():\n",
    "    operator_id = row['operator_id']\n",
    "    accum_exp = df_operators_participation_model[\n",
    "        (df_operators_participation_model['operator_id'] == operator_id) &\n",
    "        (df_operators_participation_model['production_date'] < row['production_date'])\n",
    "    ]['participation_minutes'].sum()\n",
    "    df_operators_participation_model.at[index, 'accumulated_experience'] = accum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['days_accumulated_experience'] = 0\n",
    "df_pivot['OFs_accumulated_experience'] = 0\n",
    "\n",
    "\n",
    "for index, row in df_pivot.iterrows():\n",
    "    participated_operators = row.index[row == 1].tolist()\n",
    "    participated_operators= [int(operator.split('_')[1]) for operator in participated_operators]\n",
    "    df_op_participation = df_operators_participation_model[\n",
    "        (df_operators_participation_model['operator_id'].isin(participated_operators)) &\n",
    "        (df_operators_participation_model['participation_indicator'] == 1)\n",
    "    ]\n",
    "    hours_exp_sum = df_op_participation.accumulated_experience.sum() / (60*24) # en días\n",
    "    orders_exp_sum = df_op_participation.accumulated_experience.count() # numero de participaciones OFs\n",
    "    df_pivot.at[index, 'days_accumulated_experience'] = int(hours_exp_sum)\n",
    "    df_pivot.at[index, 'OFs_accumulated_experience'] = int(orders_exp_sum)\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_of_model, df_pivot, on='order', how='left')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_operators = [col for col in df_merged.columns if 'operator_' in col]  # selecciona las columnas de operador\n",
    "df_merged['effective_operators_qty'] = df_merged[cols_operators].apply(lambda row: row.sum(), axis=1)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVISAR CASO DE OPERADOR-ORDER duplicado\n",
    "#df_operators_participation_model[(df_operators_participation_model.order == 5309158) & (df_operators_participation_model.operator_id == 1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas modelos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged.copy()\n",
    "\n",
    "TARGET = 'achieve_performance'\n",
    "exclude_columns = ['order', 'bomb_type', 'registers_qty', 'operators_distinct_qty', 'start_date', 'end_date', 'bad_qty', 'theorical_diff', 'total_operators_minutes', 'theorical_qty',\n",
    "                   'time_diff_seconds_calculated', 'time_diff_minutes_calculated',\n",
    "                   'time_diff_hours_calculated', 'performance', 'performance_category'] + [TARGET]\n",
    "FEATURES = [col for col in df.columns if col not in exclude_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características (features) y variable objetivo (target)\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X)\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el clasificador XGBoost\n",
    "classifier_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "classifier_model.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = classifier_model.predict(X_test)\n",
    "y_pred_proba = classifier_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "result = X_test.copy()\n",
    "result['prediction'] = y_pred\n",
    "result['prediction_prob'] = y_pred_proba\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del modelo: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "if save:\n",
    "    with open('classifier_model.pickle', 'wb') as file:\n",
    "        pickle.dump(classifier_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_complete = pd.concat([result, df_merged[df_merged.index.isin(result.index)].loc[:, ~df_merged.columns.isin(result.columns)]], axis=1)\n",
    "df_result_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of[df_of.order == 5294563]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result_complete[df_result_complete.achieve_performance != df_result_complete.prediction]\n",
    "df_result_complete[(df_result_complete.achieve_performance == 1) & (df_result_complete.prediction == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Realizar validación cruzada con 5 divisiones\n",
    "scores = cross_val_score(classifier_model, X_encoded, y, cv=5)\n",
    "\n",
    "# Mostrar las puntuaciones de rendimiento en cada división\n",
    "print(\"Puntuaciones de rendimiento en cada división:\", scores)\n",
    "\n",
    "# Calcular la media y desviación estándar de las puntuaciones de rendimiento\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "print(\"Media de las puntuaciones de rendimiento:\", mean_score)\n",
    "print(\"Desviación estándar de las puntuaciones de rendimiento:\", std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importances = classifier_model.feature_importances_\n",
    "\n",
    "# Obtener los nombres de las características\n",
    "feature_names = X_encoded.columns\n",
    "\n",
    "# Ordenar las importancias y los nombres de las características en orden descendente\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices][:20]\n",
    "sorted_feature_names = feature_names[indices][:20]\n",
    "\n",
    "# Visualizar la importancia de las características en un gráfico de barras\n",
    "sns.set_style('white')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_importances)), sorted_importances)\n",
    "plt.xticks(range(len(sorted_importances)), sorted_feature_names, rotation='vertical')\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia de las características')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seleccionar las columnas relevantes para el análisis\n",
    "columns = ['line_LINEA_3', 'line_LINEA_1', 'line_LINEA_2', 'good_qty', 'theorical_time', 'operator_9266', 'operator_1007', 'operator_504', 'performance']\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas seleccionadas\n",
    "df_corr = df_result_complete[columns]\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = df_corr.corr()\n",
    "\n",
    "# Imprimir la matriz de correlación\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance Permutatios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calcular la importancia de las permutaciones\n",
    "result = permutation_importance(classifier_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Obtener los puntajes de importancia\n",
    "importance_scores = result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance_perm = pd.DataFrame({'feature': X_encoded.columns, 'importance': result.importances_mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_importance_perm[df_importance_perm.importance != 0.00]\n",
    "data = df_importance_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = data.feature\n",
    "importance_scores = data.importance\n",
    "\n",
    "# Crear un gráfico de barras de la importancia de las características\n",
    "plt.figure(figsize=(10, 25))\n",
    "plt.barh(feature_names, importance_scores)\n",
    "plt.xlabel('Importancia')\n",
    "plt.ylabel('Característica')\n",
    "plt.title('Importancia de las características (Permutation Importance)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_result_complete['achieve_performance']\n",
    "y_pred = df_result_complete['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Crear el mapa de calor de la matriz de confusión\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular las probabilidades de las clases positivas\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular la tasa de falsos positivos, la tasa de verdaderos positivos y los umbrales\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Calcular el área bajo la curva ROC\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva precisión Recal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcular la precisión y la exhaustividad\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# Graficar la curva de Precisión-Recall\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regressor | Minutos-hombre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged.copy()\n",
    "\n",
    "TARGET = 'total_operators_minutes'\n",
    "exclude_columns = ['order', 'bomb_type', 'start_date', 'end_date', 'theorical_qty', 'theorical_diff',\n",
    "                   'time_diff_seconds_calculated', 'time_diff_minutes_calculated', 'performance',\n",
    "                   'time_diff_hours_calculated', 'achieve_performance', 'performance_category'] + [TARGET]\n",
    "FEATURES = [col for col in df.columns if col not in exclude_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características (features) y variable objetivo (target)\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X)\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el clasificador XGBoost\n",
    "model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, verbose=1)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "result = X_test.copy()\n",
    "result['prediction'] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "\n",
    "print(\"R-squared [R2]: %.2f\" % r2)\n",
    "print(\"Mean Absolute Error [MAE]: %.2f\" % mae)\n",
    "print(\"Mean Squared Error [MSE]: %.2f\" % mse)\n",
    "print(\"Root Mean Squared Error [RMSE]: %.2f\" % rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la variable 'predicted_performance' para comoparar la performance real versus la calculada con la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['predicted_performance'] = (result.good_qty*result.theorical_time) / result.prediction\n",
    "result.head()   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join de results with the OFs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_complete = pd.concat([result, df_merged[df_merged.index.isin(result.index)].loc[:, ~df_merged.columns.isin(result.columns)]], axis=1)\n",
    "df_result_complete.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión del modelo evaluando performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(df_result_complete.performance, df_result_complete.predicted_performance)\n",
    "mae = mean_absolute_error(df_result_complete.performance, df_result_complete.predicted_performance)\n",
    "mse = mean_squared_error(df_result_complete.performance, df_result_complete.predicted_performance)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "\n",
    "print(\"R-squared [R2]: %.2f\" % r2)\n",
    "print(\"Mean Absolute Error [MAE]: %.2f\" % mae)\n",
    "print(\"Mean Squared Error [MSE]: %.2f\" % mse)\n",
    "print(\"Root Mean Squared Error [RMSE]: %.2f\" % rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Realizar validación cruzada con 5 divisiones\n",
    "scores = cross_val_score(model, X_encoded, y, cv=5)\n",
    "\n",
    "# Mostrar las puntuaciones de rendimiento en cada división\n",
    "print(\"Puntuaciones de rendimiento en cada división:\", scores)\n",
    "\n",
    "# Calcular la media y desviación estándar de las puntuaciones de rendimiento\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "print(\"Media de las puntuaciones de rendimiento:\", mean_score)\n",
    "print(\"Desviación estándar de las puntuaciones de rendimiento:\", std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'TARGET': y_test, 'Predict': y_pred})\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Obtener los nombres de las características\n",
    "feature_names = X_encoded.columns\n",
    "\n",
    "# Ordenar las importancias y los nombres de las características en orden descendente\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices][:30]\n",
    "sorted_feature_names = feature_names[indices][:30]\n",
    "\n",
    "# Visualizar la importancia de las características en un gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_importances)), sorted_importances)\n",
    "plt.xticks(range(len(sorted_importances)), sorted_feature_names, rotation='vertical')\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia de las características')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'theorical_qty'\n",
    "# Graficar la relación entre la característica y las predicciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_result_complete[feature_name], y_pred)\n",
    "plt.xlabel(feature_name)\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Relación entre {} y las predicciones'.format(feature_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_result_complete.sort_values(by='total_operators_minutes', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=data, x='total_operators_minutes', kde=True, label='Real Minutos-hombre')\n",
    "sns.histplot(data=data, x='prediction', kde=True, label='Predicción Minutos-hombre')\n",
    "plt.xlabel('Minutos-hombre')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(f'Comparación entre Real y Predicción de Minutos-hombre')\n",
    "plt.xticks(rotation=70, ha='right', fontsize=8)\n",
    "plt.gca().legend().set_visible(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regressor | Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged.copy()\n",
    "\n",
    "TARGET = 'performance'\n",
    "exclude_columns = ['order', 'bomb_type', 'start_date', 'end_date', 'theorical_qty', 'theorical_diff',\n",
    "                   'time_diff_seconds_calculated', 'time_diff_minutes_calculated', 'total_operators_minutes',\n",
    "                   'time_diff_hours_calculated', 'achieve_performance', 'performance_category'] + [TARGET]\n",
    "FEATURES = [col for col in df.columns if col not in exclude_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características (features) y variable objetivo (target)\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X)\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el clasificador XGBoost\n",
    "model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, verbose=1)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "result = X_test.copy()\n",
    "result['prediction'] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "\n",
    "print(\"R-squared [R2]: %.2f\" % r2)\n",
    "print(\"Mean Absolute Error [MAE]: %.2f\" % mae)\n",
    "print(\"Mean Squared Error [MSE]: %.2f\" % mse)\n",
    "print(\"Root Mean Squared Error [RMSE]: %.2f\" % rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join de results with the OFs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_complete = pd.concat([result, df_merged[df_merged.index.isin(result.index)].loc[:, ~df_merged.columns.isin(result.columns)]], axis=1)\n",
    "df_result_complete.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Realizar validación cruzada con 5 divisiones\n",
    "scores = cross_val_score(model, X_encoded, y, cv=5)\n",
    "\n",
    "# Mostrar las puntuaciones de rendimiento en cada división\n",
    "print(\"Puntuaciones de rendimiento en cada división:\", scores)\n",
    "\n",
    "# Calcular la media y desviación estándar de las puntuaciones de rendimiento\n",
    "mean_score = np.mean(scores)\n",
    "std_score = np.std(scores)\n",
    "print(\"Media de las puntuaciones de rendimiento:\", mean_score)\n",
    "print(\"Desviación estándar de las puntuaciones de rendimiento:\", std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'TARGET': y_test, 'Predict': y_pred})\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Obtener los nombres de las características\n",
    "feature_names = X_encoded.columns\n",
    "\n",
    "# Ordenar las importancias y los nombres de las características en orden descendente\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_importances = importances[indices][:30]\n",
    "sorted_feature_names = feature_names[indices][:30]\n",
    "\n",
    "# Visualizar la importancia de las características en un gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_importances)), sorted_importances)\n",
    "plt.xticks(range(len(sorted_importances)), sorted_feature_names, rotation='vertical')\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia de las características')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'theorical_qty'\n",
    "# Graficar la relación entre la característica y las predicciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_result_complete[feature_name], y_pred)\n",
    "plt.xlabel(feature_name)\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Relación entre {} y las predicciones'.format(feature_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_result_complete.sort_values(by='performance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=data, x='performance', kde=True, label='Real Performance')\n",
    "sns.histplot(data=data, x='prediction', kde=True, label='Predicción Performance')\n",
    "plt.xlabel('Minutos-hombre')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title(f'Comparación entre Real y Predicción de Performance')\n",
    "plt.xticks(rotation=70, ha='right', fontsize=8)\n",
    "plt.gca().legend().set_visible(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def select_best_combo(orders, available_operators, available_lines, max_operators_per_order, model):\n",
    "    \"\"\"\n",
    "    Itera sobre todas las combinaciones posibles de operadores y lineas y selecciona la que tiene\n",
    "    la mejor predicción para todas las OFs, con la restricción de que un operador no puede trabajar\n",
    "    en más de una OF a la vez.\n",
    "    \"\"\"\n",
    "    best_prediction = np.inf  # inicializar con infinito para minimizar\n",
    "    best_order_operator_line = {}\n",
    "\n",
    "    # Creamos todas las combinaciones de operadores y líneas\n",
    "    operator_combos = []\n",
    "    for r in range(1, max_operators_per_order + 1):\n",
    "        operator_combos.extend(itertools.combinations(available_operators, r))\n",
    "    operator_line_combos = list(itertools.product(operator_combos, available_lines))\n",
    "\n",
    "    # Recorremos todas las órdenes\n",
    "    for order in orders:\n",
    "        order_best_prediction = np.inf\n",
    "        order_best_operator_line = None\n",
    "\n",
    "        # Probamos cada combinación de operador-línea para la orden\n",
    "        for operators, line in operator_line_combos:\n",
    "            # Creamos un dataframe con las características de la orden\n",
    "            order_df = pd.DataFrame({\n",
    "                'good_qty': [order['good_qty']],\n",
    "                'theorical_time': [order['theorical_time']],\n",
    "                'operators': [operators],\n",
    "                'line': [line],\n",
    "            })\n",
    "\n",
    "            # Hacemos la predicción con el modelo\n",
    "            prediction = model.predict(order_df)[0]\n",
    "\n",
    "            # Si la predicción es la mejor hasta ahora para esta orden, la guardamos\n",
    "            if prediction < order_best_prediction:\n",
    "                order_best_prediction = prediction\n",
    "                order_best_operator_line = (operators, line)\n",
    "\n",
    "        # Almacenamos la mejor combinación operador-línea para esta orden\n",
    "        best_order_operator_line[order['id']] = order_best_operator_line\n",
    "\n",
    "        # Actualizamos la mejor predicción general\n",
    "        if order_best_prediction < best_prediction:\n",
    "            best_prediction = order_best_prediction\n",
    "\n",
    "        # Eliminamos la combinación de operador-línea seleccionada de la lista de combinaciones\n",
    "        operator_line_combos = [combo for combo in operator_line_combos if not set(order_best_operator_line[0]).issubset(set(combo[0]))]\n",
    "\n",
    "    return best_order_operator_line, best_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation_model = df_operators_participation_model.sort_values(by=['operator_id', 'production_date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation_model['accumulated_experience'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_operators_participation_model.iterrows():\n",
    "    operador_actual = row['operator_id']\n",
    "    fechas_anteriores = df_operators_participation_model.loc[:index, 'production_date']\n",
    "    accumulated_experience = df_operators_participation_model[(df_operators_participation_model['operator_id'] == operador_actual) & (df_operators_participation_model['production_date'] < row['production_date'])]['participation_minutes'].sum()\n",
    "    df_operators_participation_model.at[index, 'accumulated_experience'] = accumulated_experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operators_participation_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotear el dataframe df_operators_participation para obtener las columnas de operadores\n",
    "df_operators_participation_model.drop_duplicates(inplace=True)\n",
    "df_pivot = df_operators_participation_model.pivot(index='order', columns='operator_id', values='participation_indicator')\n",
    "df_pivot = df_pivot.fillna(0)\n",
    "df_pivot.columns = ['operator_' + str(col) for col in df_pivot.columns]\n",
    "df_pivot = df_pivot.astype(int)\n",
    "print(df_pivot.shape)\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['accumulated_experience'] = 0\n",
    "\n",
    "for index, row in df_pivot.iterrows():\n",
    "    participated_operators = row.index[row == 1].tolist()\n",
    "    participated_operators= [int(operator.split('_')[1]) for operator in participated_operators]\n",
    "    exp_sum = df_operators_participation_model[\n",
    "        (df_operators_participation_model['operator_id'].isin(participated_operators)) &\n",
    "        (df_operators_participation_model['participation_indicator'] == 1)\n",
    "    ]['accumulated_experience'].sum() / (60*24) # en días\n",
    "    df_pivot.at[index, 'accumulated_experience'] = int(exp_sum)\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluidra_poetry_kernel",
   "language": "python",
   "name": "fluidra_poetry_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
